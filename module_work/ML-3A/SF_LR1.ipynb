{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Линейная регрессия. Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Реализация линейной регрессии с использованием матричных операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия выражается следующей зависимостью:\n",
    "$$y=X\\theta+\\epsilon,$$\n",
    "где $X$ — матрица объекты-признаки, $y$ — вектор целевых значений, соответствующих $X$, $\\theta$ — параметр линейной регрессии, $\\epsilon$ — некоторый шум."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из данного следует выражение для $\\theta$ как:\n",
    "$$X^Ty=X^TX\\theta \\rightarrow \\theta=(X^TX)^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем выражение для $\\theta$ с помощью операций линейной алгебры библиотеки Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАЧА Реализовать функцию, осуществляющую матричные операции для получения theta\n",
    "def linreg_linear(X, y):\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовить данные\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить параметр theta\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания для тренировочной выборки\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, вычислить theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 18.10, RMSE = 4.25\n",
      "MSE = 23.08, RMSE = 4.80\n"
     ]
    }
   ],
   "source": [
    "print_regression_metrics(y_valid, y_pred)\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_pred = lr.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Реализация линейной регрессии с использованием методов оптимизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации линейной регрессии с помощью методов оптимизации будем использовать функцию ошибки **среднего квадратичного** ([Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error)), которая является выпуклой функцией в n-мерном пространстве $\\mathbb{R}^n$ и в общем виде выглядит следующим образом:\n",
    "$$MSE = \\frac{1}{n} * \\sum_{i=1}^{n}{(y_i - a(x_i))^2}.$$\n",
    "Здесь $x_i$ — вектор-признак $i$-го объекта обучающей выборки, $y_i$ — истинное значение для $i$-го объекта, $a(x)$ — алгоритм, предсказывающий для данного объекта $x$ целевое значение, $n$ — кол-во объектов в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае линейной регрессии $MSE$ представляется как:\n",
    "$$MSE(X, y, \\theta) = \\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} = \\frac{1}{2n} \\lVert{y - X\\theta}\\rVert_{2}^{2}=\\frac{1}{2n} (y - X\\theta)^T(y - X\\theta),$$\n",
    "где $\\theta$ — параметр модели линейной регрессии, $X$ — матрица объекты-признаки, $y$ - вектор истинных значений, соответствующих $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем первый вариант представления функции ошибки и посчитаем ее градиент по параметру $\\theta$, предварительно переименовав $MSE$ в $L$:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2}$$\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} = \\frac{1}{n}X^T(X\\theta - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из полученного выражения градиента, реализуем алгоритм градиентного спуска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию вычисления градиента функции MSE\n",
    "\n",
    "def calc_mse_gradient(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, осуществляющую градиентный шаг\n",
    "# (функция должна содержать параметр величины шага alpha - learning rate)\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию цикла градиентного спуска с доп. параметрами\n",
    "# начального вектора theta и числа итераций\n",
    "\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.41647399e+246, 3.32349992e+247, 7.39564172e+247, 8.96295209e+247,\n",
       "       5.07578059e+245, 4.22030567e+246, 4.63094053e+247, 5.29083888e+248,\n",
       "       2.65643383e+247, 8.19991211e+247, 3.27135991e+249, 1.38363846e+248,\n",
       "       2.64323053e+249, 9.88835598e+247])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.    ,  88.9762, 100.    ,  27.74  ,   1.    ,   0.871 ,\n",
       "         8.78  , 100.    ,  12.1265,  24.    , 711.    ,  22.    ,\n",
       "       396.9   ,  37.97  ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверить максимальные значения по каждому признаку в данных\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "168.3704950393814\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'][np.argmax(X.std(axis=0)) + 1])\n",
    "print(np.max(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать даннные с помощью стандартной нормализации\n",
    "X, y = data['data'], data['target']\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 9.9339306 , 3.80423444, 2.42256516, 3.66839786,\n",
       "       2.73234648, 3.55504427, 1.11749449, 3.96051769, 1.66124525,\n",
       "       1.79819419, 1.63882832, 0.44105193, 3.54877081])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать theta на новых данных\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.01, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.25328063e+01, -9.21740195e-01,  1.07033639e+00,  1.06388396e-01,\n",
       "        6.86667316e-01, -2.05006416e+00,  2.68062168e+00,  1.40667969e-02,\n",
       "       -3.10608483e+00,  2.57511475e+00, -1.97802851e+00, -2.05725099e+00,\n",
       "        8.48690321e-01, -3.74025884e+00])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделать предсказания при полученных параметрах\n",
    "y_pred = X.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.90, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Посчитать значение ошибок MSE и RMSE для тренировочных данных\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-b610ad6748e4>:5: RuntimeWarning: invalid value encountered in subtract\n",
      "  return theta - alpha * theta_grad\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-630df4b47d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint_regression_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-2bde278f3fdd>\u001b[0m in \u001b[0;36mprint_regression_metrics\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_regression_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'MSE = {mse:.2f}, RMSE = {rmse:.2f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибки MSE и RMSE\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(m), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
